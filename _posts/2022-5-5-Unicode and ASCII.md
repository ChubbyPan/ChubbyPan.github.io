# 编程常识 - Unicode and ASCII编码

### **WHY**

为什么需要编码? 

为什么有这么多不同的编码格式出现? 比如Unicode,GBK,ASCII等等?

1. 计算机中的基本存储单位为byte(8 bits),所以可以表示0-255种字符;但是日常生活中,使用的文字语言不是010101的字符,我们需要把人类理解的文字转化为计算机理解的字符,这就是编码的意义.
   
2. 英文有26个字母,加上其大小写，数字0-9和一些控制符，可以在256的范围内表示完，但是比如中文或者其他国家的语言,是不够用的.而ASCII码只能表示128中不同的符号,所以需要其他类型的编码出现.

### **WHAT**

#### ASCII
一个byte, 其中0-127可以表示不同的英文字母,数字0-9以及其他的操作符比如enter,&等等.

#### Unicode
可以让世界上的每一种语言的每一个符号都有独一无二的表示,分为UTF-16\UTF-8(还有UTF-32)
- 前者为定长的编码形式,每个字符都是2 bytes表示
- 后者是变长的编码形式,网络传输中每次只传8位,根据不同的字符⽽变化字节的⻓度.同时规定⼀些规则,来⽀持其变⻓的特性。

#### **differ?**
1. size
2. ASCII == UNICODE?  即便是ASCII和UTF-8也不一样,不过为了兼容ASCII,UTF-8前128个字符和ASCII会保持一致


### **HOW**
UTF-16是定长编码,但是UTF-8是变长编码,我怎么知道具体是几个byte呢?

参考:

[How does UTF-8 represent characters?](https://stackoverflow.com/questions/54702119/how-does-utf-8-represent-characters)
   
   
